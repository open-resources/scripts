{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Firas Moosvi and Graham Bovett\n",
    "# Date: 2021-05-09\n",
    "# This file contains many helper functions that will be used across the question bank project.\n",
    "\n",
    "from docopt import docopt\n",
    "\n",
    "# Imports\n",
    "## Loading and Saving files & others\n",
    "import uuid\n",
    "import json\n",
    "#from . import prairielearn as pl\n",
    "import pathlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from shutil import copy2\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "## Parse Markdown\n",
    "from markdown_it import MarkdownIt # pip install markdown-it-py \n",
    "from mdformat.renderer import MDRenderer # pip install mdformat\n",
    "\n",
    "## Dealing with YAML\n",
    "import yaml\n",
    "\n",
    "# Start of reading/parsing functions\n",
    "\n",
    "def defdict_to_dict(defdict, finaldict):\n",
    "    \"\"\"Convert a defaultdict (nested) to a regular dictionary.\n",
    "        - Answer copied from: https://stackoverflow.com/a/61133504/2217577\n",
    "    Args:\n",
    "        defdict (dict): defaultdict\n",
    "        finaldict (dict): regular dictionary\n",
    "\n",
    "    Returns:\n",
    "        dict: Convert to regular dictionary\n",
    "    \"\"\"\n",
    "    # pass in an empty dict for finaldict\n",
    "    for k, v in defdict.items():\n",
    "        if isinstance(v, defaultdict):\n",
    "            # new level created and that is the new value\n",
    "            finaldict[k] = defdict_to_dict(v, {})\n",
    "        else:\n",
    "            finaldict[k] = v\n",
    "    return finaldict\n",
    "\n",
    "def split_body_parts(num_parts,body_parts):\n",
    "    \"\"\"Parses individual question parts and splits out titles, and content\n",
    "\n",
    "    Args:\n",
    "        num_parts (int): An integer corresponding to the number of question parts (from `read_md_problem()`).\n",
    "        body_parts (dict): A dictionary from `read_md_problem()`.\n",
    "\n",
    "    Returns:\n",
    "        body_parts_dict (dict): returns a nested dictionary with title,content,answer keys .\n",
    "    \"\"\"\n",
    "    mdit = MarkdownIt()\n",
    "    env = {}\n",
    "    nested_dict = lambda: defaultdict(nested_dict)\n",
    "\n",
    "    parts_dict = nested_dict()\n",
    "\n",
    "    for pnum in range(1,num_parts+1):\n",
    "\n",
    "        part = 'part'+f'{pnum}'\n",
    "        # Set up tokens by parsing the md file\n",
    "        tokens = mdit.parse(body_parts[part], env)\n",
    "\n",
    "        ptt = [i for i,j in enumerate(tokens) if j.tag=='h2']\n",
    "        parts_dict[part]['title'] = MDRenderer().render(tokens[ptt[0]+1:ptt[1]], mdit.options, env).strip('\\n')\n",
    "\n",
    "        pa = [i for i,j in enumerate(tokens) if j.tag=='h3']\n",
    "\n",
    "        try:\n",
    "            parts_dict[part]['answer']['title'] = codecs.unicode_escape_decode(MDRenderer().render(tokens[pa[0]+1:pa[1]], mdit.options, env))[0]\n",
    "        except IndexError:\n",
    "            print(\"Check the heading levels, is there one that doesn't belong? Or is the heading level incorrect? For e.g., it should be ### Answer Section (this is not necessarily where the issue is).\")\n",
    "            raise\n",
    "\n",
    "        parts_dict[part]['content'] = codecs.unicode_escape_decode(MDRenderer().render(tokens[ptt[1]+1:pa[0]], mdit.options, env))[0]\n",
    "        parts_dict[part]['answer']['content'] = codecs.unicode_escape_decode(MDRenderer().render(tokens[pa[1]+1:], mdit.options, env))[0]\n",
    "\n",
    "        # Remove parts from body_parts\n",
    "        body_parts.pop(part)\n",
    "\n",
    "    # Deal with other headings: pl-submission-panel and pl-answer-panel\n",
    "\n",
    "    for key in body_parts.keys():\n",
    "        if key in ['pl-submission-panel','pl-answer-panel']:\n",
    "            # Set up tokens by parsing the md file\n",
    "            tokens = mdit.parse(body_parts[key], env)\n",
    "\n",
    "            ptt = [i for i,j in enumerate(tokens) if j.tag=='h2']\n",
    "            parts_dict[key] = codecs.unicode_escape_decode(MDRenderer().render(tokens[ptt[-1]+1:], mdit.options, env))[0]\n",
    "\n",
    "    return defdict_to_dict(parts_dict,{})\n",
    "\n",
    "def read_md_problem(filepath):\n",
    "    \"\"\"Reads a MystMarkdown problem file and returns a dictionary of the header and body\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path of file to read.\n",
    "\n",
    "    Returns:\n",
    "        dict: In this dictionary there are three keys containing useful portions of the parsed md file: \n",
    "            - `header` - Header of the problem file (nested dictionary).\n",
    "            - `body_parts` - Body text of the problem file (nested dictionary).\n",
    "            - `num_parts` - Number of parts in the problem (integer).\n",
    "    \"\"\"\n",
    "\n",
    "    mdtext = pathlib.Path(filepath).read_text(encoding='utf8')\n",
    "\n",
    "    # Deal with YAML header\n",
    "    header_text = mdtext.rsplit('---\\n')[1]\n",
    "    header = yaml.safe_load('---\\n' + header_text)\n",
    "\n",
    "    # Deal with Markdown Body\n",
    "    body = mdtext.rsplit('---\\n')[2]\n",
    "    \n",
    "    # Set up the markdown parser\n",
    "    # to be honest, not fully sure what's going on here, see this issue: https://github.com/executablebooks/markdown-it-py/issues/164\n",
    "\n",
    "    mdit = MarkdownIt()\n",
    "    env = {}\n",
    "\n",
    "    # Set up tokens by parsing the md file\n",
    "    tokens = mdit.parse(body, env)\n",
    "\n",
    "    blocks = {}\n",
    "\n",
    "    block_count = 0\n",
    "\n",
    "    num_titles = 0\n",
    "\n",
    "    for x,t in enumerate(tokens):\n",
    "\n",
    "        if t.tag == 'h1' and t.nesting == 1: # title\n",
    "            # oh boy. this is going to break and it will be your fault firas.\n",
    "            blocks['title'] = [x,x+3]\n",
    "            num_titles += 1\n",
    "\n",
    "        elif t.tag == 'h2' and t.nesting == 1:\n",
    "            block_count += 1\n",
    "\n",
    "            if block_count == 1:\n",
    "                blocks['block{0}'.format(block_count)] = [x,]\n",
    "            else:\n",
    "                blocks['block{0}'.format(block_count-1)].append(x)\n",
    "                blocks['block{0}'.format(block_count)] = [x,]\n",
    "\n",
    "    # Add -1 to the end of the last block\n",
    "    blocks['block{0}'.format(block_count)].append(len(tokens))\n",
    "\n",
    "    # Assert statements (turn into tests!)\n",
    "    assert num_titles == 1, \"I see {0} Level 1 Headers (#) in this file, there should only be one!\".format(num_titles)\n",
    "    assert block_count >= 1, \"I see {0} Level 2 Headers (##) in this file, there should be at least 1\".format(block_count -1)\n",
    "\n",
    "    # Add the end of the title block; # small hack\n",
    "    #blocks['title'].append(blocks['block1'][0])\n",
    "\n",
    "    # Get the preamble before the parts start\n",
    "    blocks['preamble'] = [blocks['title'][1],blocks['block1'][0]]\n",
    "\n",
    "    ## Process the blocks into markdown\n",
    "\n",
    "    body_parts = {}\n",
    "\n",
    "    part_counter = 0\n",
    "\n",
    "    for k,v in blocks.items():\n",
    "\n",
    "        rendered_part = codecs.unicode_escape_decode(MDRenderer().render(tokens[v[0]:v[1]], mdit.options, env))[0]\n",
    "        \n",
    "        if k == 'title':\n",
    "            body_parts['title'] = rendered_part\n",
    "        \n",
    "        elif k == 'preamble':\n",
    "            body_parts['preamble'] = rendered_part\n",
    "\n",
    "        elif 'Rubric' in rendered_part:\n",
    "            body_parts['Rubric'] = rendered_part\n",
    "\n",
    "        elif 'Solution' in rendered_part:\n",
    "            body_parts['Solution'] = rendered_part\n",
    "\n",
    "        elif 'Comments' in rendered_part:\n",
    "            body_parts['Comments'] = rendered_part\n",
    "\n",
    "        elif 'pl-submission-panel' in rendered_part:\n",
    "            body_parts['pl-submission-panel'] = rendered_part\n",
    "\n",
    "        elif 'pl-answer-panel' in rendered_part:\n",
    "            body_parts['pl-answer-panel'] = rendered_part\n",
    "\n",
    "        else:\n",
    "            part_counter +=1\n",
    "            body_parts[f'part{part_counter}'] = rendered_part\n",
    "\n",
    "    return_dict = {'header': header,\n",
    "            'body_parts': body_parts,\n",
    "            'num_parts': part_counter,\n",
    "            'body_parts_split': split_body_parts(part_counter,body_parts.copy()) \n",
    "            }\n",
    "    return defdict_to_dict(return_dict,{})\n",
    "\n",
    "def dict_to_md(md_dict, remove_keys = [None,]):\n",
    "    \"\"\" Takes a nested dictionary (e.g. output of read_md_problem()) and returns a multi-line string  that can be written to a file (after removing specified keys).   \n",
    "    Args:\n",
    "        md_dict (dict): A nested dictionary, for e.g. the output of `read_md_problem()`\n",
    "        remove_keys (list, optional): Any keys to remove from the dictionary, for instance solutions. Defaults to [None,].\n",
    "\n",
    "    Returns:\n",
    "        str: A multi-line string that can be written to a file.\n",
    "    \"\"\"\n",
    "\n",
    "    md_string = \"\"\n",
    "\n",
    "    md_dict = defdict_to_dict(md_dict,{})\n",
    "\n",
    "    # Question Title and Preamble\n",
    "    md_string += md_dict.pop('title',None)\n",
    "    md_string += md_dict.pop('preamble',None)\n",
    "\n",
    "    for k,v in md_dict.items():\n",
    "        if k in remove_keys:\n",
    "            continue\n",
    "        else:\n",
    "            md_string += md_dict[k]\n",
    "\n",
    "    return md_string\n",
    "\n",
    "## Functions from md-to-pl\n",
    "\n",
    "def write_info_json(output_path, parsed_question):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        output_path (Path): [description]\n",
    "        parsed_question (dict]): [description]\n",
    "    \"\"\"\n",
    "\n",
    "    pathlib.Path(output_path / 'info.json').write_text(\"\"\"{\n",
    "            \"uuid\": \\\"\"\"\" + str(uuid.uuid3(uuid.NAMESPACE_DNS, str(output_path))) + \"\"\"\\\",\n",
    "            \"title\": \\\"\"\"\" + parsed_question['header']['title'] + \"\"\"\",\n",
    "            \"topic\": \\\"\"\"\" + parsed_question['header']['topic'] + \"\"\"\",\n",
    "            \"tags\":  \"\"\" + json.dumps(parsed_question['header']['tags']) + \"\"\",\n",
    "            \"type\": \"v3\"\n",
    "        }\"\"\",encoding='utf8')\n",
    "\n",
    "def write_server_py(output_path,parsed_question):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        output_path ([type]): [description]\n",
    "        parsed_question ([type]): [description]\n",
    "    \"\"\"\n",
    "    \n",
    "    output_path = pathlib.Path(output_path)\n",
    "    \n",
    "    server_dict = parsed_question['header']['server']\n",
    "    \n",
    "    server_file = f\"\"\"\"\"\"\n",
    "    \n",
    "    server_file += server_dict.pop('imports',None) + '\\n'\n",
    "    \n",
    "    try:\n",
    "        for function, code in server_dict.items():\n",
    "            indented_code = code.replace('\\n','\\n    ')\n",
    "            if code:\n",
    "                server_file += f\"def {function}(data):\\n    {indented_code}\\n\"\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "    # Deal with path differences when using PL\n",
    "    server_file = server_file.replace('read_csv(\"',\n",
    "                                      'read_csv(data[\"options\"][\"client_files_course_path\"]+\"/')\n",
    "\n",
    "    # Write server.py\n",
    "    (output_path / \"server.py\").write_text(server_file,encoding='utf8')\n",
    "\n",
    "def process_multiple_choice(part_name,parsed_question, data_dict):\n",
    "    \"\"\"Processes markdown format multiple-choice questions and returns PL HTML\n",
    "    Args:\n",
    "        output_path (Path): [description]\n",
    "        parsed_question (dict): [description]\n",
    "        data_dict (dict)\n",
    "    \n",
    "    Returns:\n",
    "        str: Multiple choice question is returned as a string with PL-compliant syntax.\n",
    "    \"\"\"\n",
    "\n",
    "    html = f\"\"\"<pl-question-panel>\\n<markdown>{parsed_question['body_parts_split'][part_name]['content']}</markdown>\\n</pl-question-panel>\\n\\n\"\"\"\n",
    "    \n",
    "    pl_customizations = \" \".join([f'{k} = \"{v}\"' for k,v in parsed_question['header'][part_name]['pl-customizations'].items()]) # PL-customizations\n",
    "    html += f\"\"\"<pl-multiple-choice answers-name=\"{part_name}_ans\" {pl_customizations} >\\n\"\"\"\n",
    "\n",
    "    if data_dict['params'][f'vars']['units']:\n",
    "        units = f\"|@ params.vars.units @|\"\n",
    "    else:\n",
    "        units = ''\n",
    "\n",
    "    for a in data_dict['params'][f'{part_name}'].keys():\n",
    "        if 'ans' in a:\n",
    "            html += f\"\\t<pl-answer correct= |@ params.{part_name}.{a}.correct @| > |@ params.{part_name}.{a}.value @| {units} </pl-answer>\\n\"\n",
    "\n",
    "    html += '</pl-multiple-choice>\\n' \n",
    "\n",
    "    return replace_tags(html)\n",
    "\n",
    "def process_dropdown(part_name,parsed_question, data_dict):\n",
    "    \"\"\"Processes markdown format dropdown questions and returns PL HTML\n",
    "\n",
    "    Args:\n",
    "        part_name (string): Name of the question part being processed (e.g., part1, part2, etc...)\n",
    "        parsed_question (dict): Dictionary of the MD-parsed question (output of `read_md_problem`)\n",
    "        data_dict (dict): Dictionary of the `data` dict created after running server.py using `exec()`\n",
    "\n",
    "    Returns:\n",
    "        html: A string of HTML that is part of the final PL question.html file.\n",
    "    \"\"\"\n",
    "    html = process_multiple_choice(part_name,parsed_question, data_dict).replace('-multiple-choice','-dropdown')\n",
    "    return html\n",
    "    \n",
    "def process_number_input(part_name,parsed_question, data_dict):\n",
    "    \"\"\"Processes markdown format number-input questions and returns PL HTML\n",
    "\n",
    "    Args:\n",
    "        part_name (string): Name of the question part being processed (e.g., part1, part2, etc...)\n",
    "        parsed_question (dict): Dictionary of the MD-parsed question (output of `read_md_problem`)\n",
    "        data_dict (dict): Dictionary of the `data` dict created after running server.py using `exec()`\n",
    "\n",
    "    Returns:\n",
    "        html: A string of HTML that is part of the final PL question.html file.\n",
    "    \"\"\"\n",
    "\n",
    "    html = f\"\"\"<pl-question-panel>\\n\\t<markdown>{parsed_question['body_parts_split'][part_name]['content']}\\t</markdown>\\n</pl-question-panel>\\n\\n\"\"\"\n",
    "    \n",
    "    pl_customizations = \" \".join([f'{k} = \"{v}\"' for k,v in parsed_question['header'][part_name]['pl-customizations'].items()]) # PL-customizations\n",
    "    html += f\"\"\"<pl-number-input answers-name=\"{part_name}_ans\" {pl_customizations} ></pl-number-input>\\n\"\"\"\n",
    "\n",
    "    return replace_tags(html)\n",
    "\n",
    "def process_checkbox(part_name,parsed_question, data_dict):\n",
    "    \"\"\"Processes markdown format checkbox (select all that apply) questions and returns PL HTML\n",
    "\n",
    "    Args:\n",
    "        part_name (string): Name of the question part being processed (e.g., part1, part2, etc...)\n",
    "        parsed_question (dict): Dictionary of the MD-parsed question (output of `read_md_problem`)\n",
    "        data_dict (dict): Dictionary of the `data` dict created after running server.py using `exec()`\n",
    "\n",
    "    Returns:\n",
    "        html: A string of HTML that is part of the final PL question.html file.\n",
    "    \"\"\"\n",
    "    # start with the MCQ version and then...change things for checkbox questions\n",
    "    html = process_multiple_choice(part_name,parsed_question, data_dict).replace('-multiple-choice','-checkbox')\n",
    "\n",
    "    \n",
    "    return html\n",
    "\n",
    "def process_symbolic_input(part_name,parsed_question, data_dict):\n",
    "    \"\"\"Processes markdown format symbolic questions and returns PL HTML\n",
    "\n",
    "    Args:\n",
    "        part_name (string): Name of the question part being processed (e.g., part1, part2, etc...)\n",
    "        parsed_question (dict): Dictionary of the MD-parsed question (output of `read_md_problem`)\n",
    "        data_dict (dict): Dictionary of the `data` dict created after running server.py using `exec()`\n",
    "\n",
    "    Returns:\n",
    "        html: A string of HTML that is part of the final PL question.html file.\n",
    "    \"\"\"\n",
    "\n",
    "    html = f\"\"\"<pl-question-panel>\\n\\t<markdown>{parsed_question['body_parts_split'][part_name]['content']}\\t</markdown>\\n</pl-question-panel>\\n\\n\"\"\"\n",
    "    \n",
    "    pl_customizations = \" \".join([f'{k} = \"{v}\"' for k,v in parsed_question['header'][part_name]['pl-customizations'].items()]) # PL-customizations\n",
    "    html += f\"\"\"<pl-symbolic-input answers-name=\"{part_name}_ans\" {pl_customizations} ></pl-symbolic-input>\\n\"\"\"\n",
    "\n",
    "    return replace_tags(html).replace('\\\\\\\\','\\\\')\n",
    "\n",
    "def replace_tags(string):\n",
    "    \"\"\"Takes in a string with tags: |@ and @| and returns {{ and }} respectively. This is because Python strings can't have double curly braces.\n",
    "\n",
    "    Args:\n",
    "        string (str): String to be processed, can be multi-line.\n",
    "\n",
    "    Returns:\n",
    "        string (str): returns string with tags replaced with curly braces.\n",
    "    \"\"\"\n",
    "    return string.replace('|@','{{').replace('@|','}}')\n",
    "\n",
    "def remove_correct_answers(data2_dict):\n",
    "    \"\"\"Magical recursive function that removes particular keys from a nested dictionary: https://stackoverflow.com/a/29652561/2217577\n",
    "\n",
    "    Args:\n",
    "        data2_dict (dict): Dictionary (nested) from which to remove key:value\n",
    "\n",
    "    Returns:\n",
    "        data2_dict (dict): Dictionary with the offending keys removed\n",
    "    \"\"\"\n",
    "\n",
    "    # This was adapted from this SO: https://stackoverflow.com/a/29652561/2217577\n",
    "    def gen_dict_extract(key_to_remove, dict_object):\n",
    "        if hasattr(dict_object,'items'):\n",
    "            for k, v in list(dict_object.items()):\n",
    "                if key_to_remove in k:\n",
    "                    dict_object.pop(k,None)\n",
    "                if isinstance(v, dict):\n",
    "                    for result in gen_dict_extract(key_to_remove, v):\n",
    "                        yield result\n",
    "                elif isinstance(v, list):\n",
    "                    for d in v:\n",
    "                        for result in gen_dict_extract(key_to_remove, d):\n",
    "                            yield result\n",
    "\n",
    "    list(gen_dict_extract('correct',data2_dict))\n",
    "\n",
    "    return data2_dict\n",
    "\n",
    "def process_attribution(source):\n",
    "    \"\"\"Takes in a string and returns the HTML for the attribution\n",
    "\n",
    "    Args:\n",
    "        source (string): One of a set of pre-defined values corresponding to a particular attribution.\n",
    "\n",
    "    Returns:\n",
    "        string (str): returns the html of the attribution\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if 'openstax-physics-vol1' in source:\n",
    "            attribution_text = \"Problem is from the [OpenStax University Physics Volume 1](https://openstax.org/details/books/university-physics-volume-1) textbook, licensed under the [CC-BY 4.0 license](https://creativecommons.org/licenses/by/4.0/).<br>![Image representing the Creative Commons 4.0 BY license.](https://raw.githubusercontent.com/firasm/bits/master/by.png)\"\n",
    "\n",
    "        elif 'openstax-physics-vol2' in source:\n",
    "            attribution_text = \"Problem is from the [OpenStax University Physics Volume 2](https://openstax.org/details/books/university-physics-volume-2) textbook, licensed under the [CC-BY 4.0 license](https://creativecommons.org/licenses/by/4.0/).<br>![Image representing the Creative Commons 4.0 BY license.](https://raw.githubusercontent.com/firasm/bits/master/by.png)\"\n",
    "\n",
    "        elif 'ubc-mech2' in source:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        elif 'standard' in source:\n",
    "            attribution_text = \"Problem is licensed under the [CC-BY-NC-SA 4.0 license](https://creativecommons.org/licenses/by-nc-sa/4.0/).<br> ![The Creative Commons 4.0 license requiring attribution-BY, non-commercial-NC, and share-alike-SA license.](https://raw.githubusercontent.com/firasm/bits/master/by-nc-sa.png)\"\n",
    "    \n",
    "        return attribution_text\n",
    "    \n",
    "    except TypeError:\n",
    "        print(\"You probably need to update the template, the 'attribution' key seems to be missing.\")\n",
    "        \n",
    "def process_question_md(source_filepath, output_path = None, instructor = False):\n",
    "    \n",
    "    try:\n",
    "        pathlib.Path(source_filepath)\n",
    "    except:\n",
    "        print(f\"{source_filepath} - File does not exist.\")\n",
    "        raise\n",
    "        \n",
    "    if output_path is None:\n",
    "        if instructor: \n",
    "            # Set the output path (hard-coded)\n",
    "            output_path = pathlib.Path(source_filepath.replace('source','output/instructor'))\n",
    "        else:\n",
    "            # Set the output path (hard-coded)\n",
    "            output_path = pathlib.Path(source_filepath.replace('source','output/public'))\n",
    "    else:\n",
    "        ## TODO: Make this a bit more robust\n",
    "        output_path = pathlib.Path(output_path)\n",
    "        print(f\"Warning: This feature (specifying your own directory {output_path}) is not tested!\")\n",
    "\n",
    "    # deal with multi-line strings in YAML Dump\n",
    "    ## Code copied from here: https://stackoverflow.com/a/33300001/2217577\n",
    "\n",
    "    def str_presenter(dumper, data2):\n",
    "        if len(data2.splitlines()) > 1:  # check for multiline string\n",
    "            #data2 = re.sub('\\\\n[\\s].*\\\\n','\\n\\n',data2)\n",
    "            return dumper.represent_scalar('tag:yaml.org,2002:str', data2, style='|')\n",
    "        return dumper.represent_scalar('tag:yaml.org,2002:str', data2)\n",
    "\n",
    "    yaml.add_representer(str, str_presenter)\n",
    "\n",
    "    parsed_q = read_md_problem(source_filepath)\n",
    "\n",
    "    header = parsed_q['header']\n",
    "    body_parts = parsed_q['body_parts']\n",
    "    \n",
    "    # Run the python code\n",
    "    ## TODO: Is there a better way to do this?\n",
    "    exec(parsed_q['header']['server']['imports'].replace('import prairielearn as pl','from . import prairielearn as pl'),globals() )\n",
    "    exec(parsed_q['header']['server']['generate'].split('# Update the data object with a new dict')[0],globals() )     \n",
    "\n",
    "    # Remove the solutions from the server section\n",
    "    if instructor is False:\n",
    "        # Remove python solution from the public view\n",
    "        header.pop('server',None)\n",
    "\n",
    "        # Remove correct answers from the data2 dict \n",
    "        data2_sanitized = defdict_to_dict(data2,{})\n",
    "        data2_sanitized = remove_correct_answers(data2_sanitized)\n",
    "\n",
    "        # Update the YAML header to add substitutions \n",
    "        header.update({'substitutions': defdict_to_dict(data2_sanitized,{})})\n",
    "\n",
    "        # Update the YAML header to add substitutions, unsort it, and process for file\n",
    "        header_yml = yaml.dump(header,sort_keys=False,allow_unicode=True)\n",
    "\n",
    "        # Write the YAML to a file\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_path.write_text('---\\n' + header_yml + '---\\n' + dict_to_md(body_parts,remove_keys=['Rubric','Solution','Comments','pl-submission-panel','pl-answer-panel']) +\n",
    "                        '\\n## Attribution\\n\\n' + process_attribution(header.get('attribution')),encoding='utf8')\n",
    "        \n",
    "    else:\n",
    "        # Update the YAML header to add substitutions \n",
    "        header.update({'substitutions': defdict_to_dict(data2,{})})\n",
    "\n",
    "        return {'header':header,\n",
    "                'body_parts':body_parts,\n",
    "                'output_path':output_path}\n",
    "\n",
    "        # Update the YAML header to add substitutions, unsort it, and process for file\n",
    "        header_yml = yaml.dump(header,sort_keys=False,allow_unicode=True)\n",
    "\n",
    "        # Write the YAML to a file\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        output_path.write_text('---\\n' + header_yml + '---\\n' + dict_to_md(body_parts,remove_keys=['pl-submission-panel','pl-answer-panel']) +\n",
    "                        '\\n## Attribution\\n\\n' + process_attribution(header.get('attribution')) ,encoding='utf8')\n",
    "\n",
    "    # Move image assets\n",
    "    files_to_copy = header.get('assets')\n",
    "    if files_to_copy:\n",
    "        [copy2(pathlib.Path(source_filepath).parent / fl, output_path.parent) for fl in files_to_copy]\n",
    "\n",
    "def process_question_pl(source_filepath, output_path = None):\n",
    "\n",
    "    try:\n",
    "        pathlib.Path(source_filepath)\n",
    "    except:\n",
    "        print(f\"{source_filepath} - File does not exist.\")\n",
    "        raise\n",
    "\n",
    "    if output_path is None:\n",
    "        output_path = pathlib.Path(source_filepath.replace('source','output/prairielearn')).parent\n",
    "    else:\n",
    "        output_path = pathlib.Path(output_path).parent\n",
    "\n",
    "        ## TODO: Make this a bit more robust\n",
    "        print(f\"Warning: This feature (specifying your own directory {output_path}) is not tested!\")\n",
    "\n",
    "    # Parse the MD file\n",
    "    parsed_q = read_md_problem(source_filepath)\n",
    "\n",
    "    # Create output dir if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ############### Start Sketchiest Part\n",
    "    # Run the python code\n",
    "    try:\n",
    "        exec(parsed_q['header']['server']['imports'],globals() )\n",
    "        exec(parsed_q['header']['server']['generate'].split('# Update the data object with a new dict')[0],globals() )\n",
    "    except ModuleNotFoundError:\n",
    "        # AWFUL AWFUL hack because of the prairielearn.py file\n",
    "        exec(parsed_q['header']['server']['imports'].replace('import prairielearn as pl','from . import prairielearn as pl'),globals() )\n",
    "        exec(parsed_q['header']['server']['generate'].split('# Update the data object with a new dict')[0],globals() )     \n",
    "    ############### End Sketchiest Part\n",
    "\n",
    "    # Write info.json file\n",
    "    write_info_json(output_path, parsed_q)\n",
    "\n",
    "    # Question Preamble\n",
    "    if parsed_q['body_parts']['preamble']:\n",
    "        question_html = f\"<pl-question-panel>\\n<markdown>\\n{ parsed_q['body_parts']['preamble'] }\\n</markdown>\\n</pl-question-panel>\\n\\n\"\n",
    "    else:\n",
    "        question_html = f\"\"\n",
    "\n",
    "    ## Single part questions\n",
    "    if parsed_q['num_parts'] == 1:\n",
    "        q_type = parsed_q['header']['part1']['type']\n",
    "        if 'multiple-choice' in q_type:\n",
    "            question_html += process_multiple_choice('part1',parsed_q,data2)\n",
    "        elif 'number-input' in q_type:\n",
    "            question_html += process_number_input('part1',parsed_q,data2)\n",
    "        elif 'checkbox' in q_type:\n",
    "            question_html += process_checkbox('part1',parsed_q,data2)\n",
    "        elif 'symbolic-input' in q_type:\n",
    "            question_html += process_symbolic_input('part1',parsed_q,data2)\n",
    "        elif 'dropdown' in q_type:\n",
    "            question_html += process_dropdown('part1',parsed_q,data2)\n",
    "        else:\n",
    "            raise NotImplementedError(f\"This question type ({q_type}) is not yet implemented.\")\n",
    "\n",
    "    ##### Multi part\n",
    "    else:\n",
    "        for pnum in range(1, parsed_q['num_parts'] + 1):\n",
    "            part = 'part'+f'{pnum}'\n",
    "            q_type = parsed_q['header'][part]['type']\n",
    "\n",
    "            question_html += f\"\"\"<div class=\"card my-2\">\n",
    "<div class=\"card-header\">{parsed_q['body_parts_split'][part]['title']}</div>\\n\n",
    "<div class=\"card-body\">\\n\\n\"\"\"\n",
    "\n",
    "            if 'multiple-choice' in q_type:                \n",
    "                question_html += f\"{process_multiple_choice(part,parsed_q,data2)}\"  \n",
    "            elif 'number-input' in q_type:\n",
    "                question_html += f\"{process_number_input(part,parsed_q,data2)}\"\n",
    "            elif 'checkbox' in q_type:\n",
    "                question_html += process_checkbox(part,parsed_q,data2)\n",
    "            elif 'symbolic-input' in q_type:\n",
    "                question_html += process_symbolic_input(part,parsed_q,data2)\n",
    "            elif 'dropdown' in q_type:\n",
    "                question_html += process_dropdown(part,parsed_q,data2)\n",
    "            else:\n",
    "                raise NotImplementedError(f\"This question type ({q_type}) is not yet implemented.\")\n",
    "\n",
    "            question_html += \"</div>\\n</div>\\n\\n\\n\"\n",
    "\n",
    "    # Add pl-submission-panel and pl-answer-panel (if they exist)\n",
    "    subm_panel = parsed_q['body_parts_split'].get('pl-submission-panel', None)\n",
    "    q_panel = parsed_q['body_parts_split'].get('pl-answer-panel', None)\n",
    "\n",
    "    if subm_panel:\n",
    "        question_html += f\"<pl-submission-panel>{ parsed_q['body_parts_split']['pl-submission-panel'] } </pl-submission-panel>\\n\"\n",
    "\n",
    "    if q_panel:\n",
    "        question_html += f\"<pl-answer-panel>{ parsed_q['body_parts_split']['pl-answer-panel'] } </pl-answer-panel>\\n\"\n",
    "\n",
    "    # Add Attribution\n",
    "    question_html += f\"\\n<pl-question-panel>\\n<markdown>\\n\\n---\\n{process_attribution(parsed_q['header'].get('attribution'))}\\n</markdown>\\n</pl-question-panel>\\n\"\n",
    "\n",
    "    # Fix Latex underscore bug (_ being replaced with \\_)\n",
    "    question_html = question_html.replace('\\\\_','_')\n",
    "\n",
    "    # Final pre-processing\n",
    "    question_html = pl_image_path(question_html)\n",
    "\n",
    "    # Write question.html file\n",
    "    (output_path / \"question.html\").write_text(question_html,encoding='utf8')\n",
    "\n",
    "    ### TODO solve the issue with the latex escape sequences, this is a workaround\n",
    "    # with open((output_path / \"question.html\"), \"w\") as qfile:\n",
    "    #     print(f\"{question_html}\", file=qfile)\n",
    "\n",
    "    # Write server.py file\n",
    "    write_server_py(output_path,parsed_q)\n",
    "\n",
    "    # Move image assets\n",
    "    files_to_copy = parsed_q['header'].get('assets')\n",
    "    if files_to_copy:\n",
    "        pl_path =  output_path / \"clientFilesQuestion\"\n",
    "        pl_path.mkdir(parents=True, exist_ok=True)\n",
    "        [copy2(pathlib.Path(source_filepath).parent / fl, pl_path / fl) for fl in files_to_copy]\n",
    "\n",
    "def pl_image_path(html):\n",
    "\n",
    "    \"\"\"Adds `{{options.client_files_question_url}}` directory before the path automatically\n",
    "    \"\"\"\n",
    "\n",
    "    # If image files are included as markdown format, add {{options.client_files_question_url}}\n",
    "    res = re.subn(r\"\\(((?!http).*\\.png)\\)\",'({{options.client_files_question_url}}/\\\\1)',html)\n",
    "\n",
    "    # If image files are included as html format, add {{options.client_files_question_url}}\n",
    "    res = re.subn(r\"src=\\\"(?!http)(.*\\.png)\",\n",
    "              \"src=\\\"{{options.client_files_question_url}}/\\\\1\",res[0]) # works\n",
    "\n",
    "    return res[0]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sfp = '/Users/firasm/Sync/EL/Physics OER Bank/problem_bank_scripts/tests/test_question_templates/question_inputs/q04_checkbox/q04_checkbox.md'\n",
    "    process_question_md(sfp, instructor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: This feature (specifying your own directory dump/exp.md) is not tested!\n"
     ]
    }
   ],
   "source": [
    "ret = process_question_md('./q04_checkbox.md',output_path='./dump/exp.md',instructor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "  data2 = pbh.create_data2()\n",
      "\n",
      "  # define or load names/items/objects\n",
      "  names = pd.read_csv(\"data/names.csv\")[\"Names\"].tolist()\n",
      "\n",
      "  # store phrases etc\n",
      "  data2[\"params\"][\"vars\"][\"title\"] = \"Vectors and Scalars\"\n",
      "  data2[\"params\"][\"vars\"][\"name\"] = random.choice(names)\n",
      "\n",
      "  # define useful variables/lists\n",
      "  vectors = [\"displacement\", \"velocity\", \"acceleration\", \"momentum\", \"force\", \"lift\", \"drag\", \"thurst\", \"weight\"]\n",
      "  scalars = [\"length\", \"area\", \"volume\", \"mass\", \"density\", \"pressure\", \"temperature\", \"energy\", \"entropy\", \"work\", \"power\"]\n",
      "\n",
      "  # Randomly select 2,3,4 scalars and shuffle the lists\n",
      "  total_choices = 6\n",
      "  num_scalars = random.choice([2,3,4])\n",
      "  num_vectors = total_choices - num_scalars\n",
      "  select = random.choice([\"vectors\",\"scalars\"])\n",
      "\n",
      "  data2[\"params\"][\"choice\"] = select\n",
      "\n",
      "  # Create ans_choices\n",
      "  ans_choices = [\"ans{0}\".format(i+1) for i in range(total_choices)]\n",
      "\n",
      "  random.shuffle(scalars)\n",
      "  random.shuffle(vectors)\n",
      "\n",
      "  # define useful variables/lists\n",
      "  vectors = [\"displacement\", \"velocity\", \"acceleration\", \"momentum\", \"force\", \"lift\", \"drag\", \"thurst\", \"weight\"]\n",
      "  scalars = [\"length\", \"area\", \"volume\", \"mass\", \"density\", \"pressure\", \"temperature\", \"energy\", \"entropy\", \"work\", \"power\"]\n",
      "\n",
      "  # Randomly select 2,3,4 scalars and shuffle the lists\n",
      "  total_choices = 6\n",
      "  num_scalars = random.choice([2,3,4])\n",
      "  num_vectors = total_choices - num_scalars\n",
      "  select = random.choice([\"vectors\",\"scalars\"])\n",
      "\n",
      "  data2[\"params\"][\"choice\"] = select\n",
      "\n",
      "  # Create ans_choices\n",
      "  ans_choices = [\"ans{0}\".format(i+1) for i in range(total_choices)]\n",
      "\n",
      "  random.shuffle(scalars)\n",
      "  random.shuffle(vectors)\n",
      "\n",
      "  # define possible answers\n",
      "  if select == \"vectors\":\n",
      "      for i in range(num_vectors):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = vectors.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = True\n",
      "\n",
      "      for i in range(num_scalars):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = scalars.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = False\n",
      "\n",
      "  elif select == \"scalars\":\n",
      "      for i in range(num_scalars):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = scalars.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(ret['header']['server']['test'],sort_keys=False,allow_unicode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|\n",
      "  data2 = pbh.create_data2()\n",
      "\n",
      "  # define or load names/items/objects\n",
      "  names = pd.read_csv(\"data/names.csv\")[\"Names\"].tolist()\n",
      "\n",
      "  # store phrases etc\n",
      "  data2[\"params\"][\"vars\"][\"title\"] = 'Vectors and Scalars'\n",
      "  data2[\"params\"][\"vars\"][\"name\"] = random.choice(names)\n",
      "\n",
      "  # define useful variables/lists\n",
      "  vectors = [\"displacement\", \"velocity\", \"acceleration\", \"momentum\", \"force\", \"lift\", \"drag\", \"thurst\", \"weight\"]\n",
      "  scalars = [\"length\", \"area\", \"volume\", \"mass\", \"density\", \"pressure\", \"temperature\", \"energy\", \"entropy\", \"work\", \"power\"]\n",
      "\n",
      "  # Randomly select 2,3,4 scalars and shuffle the lists\n",
      "  total_choices = 6\n",
      "  num_scalars = random.choice([2,3,4])\n",
      "  num_vectors = total_choices - num_scalars\n",
      "  select = random.choice([\"vectors\",\"scalars\"])\n",
      "\n",
      "  data2[\"params\"][\"choice\"] = select\n",
      "\n",
      "  # Create ans_choices\n",
      "  ans_choices = [\"ans{0}\".format(i+1) for i in range(total_choices)]\n",
      "\n",
      "  random.shuffle(scalars)\n",
      "  random.shuffle(vectors)\n",
      "\n",
      "  # define possible answers\n",
      "  if select == \"vectors\":\n",
      "      for i in range(num_vectors):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = vectors.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = True\n",
      "\n",
      "      for i in range(num_scalars):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = scalars.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = False\n",
      "\n",
      "  elif select == \"scalars\":\n",
      "      for i in range(num_scalars):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = scalars.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = True\n",
      "\n",
      "      for i in range(num_vectors):\n",
      "          choice = ans_choices.pop(0)\n",
      "          data2[\"params\"][\"part1\"][choice][\"value\"] = vectors.pop()\n",
      "          data2[\"params\"][\"part1\"][choice][\"correct\"] = False\n",
      "  # Update the data object with a new dict\n",
      "  data.update(data2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(yaml.dump(ret['header']['server']['generate'],sort_keys=False,allow_unicode=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
